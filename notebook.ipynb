{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import ssl # Quickfix to torchaudio ssl error\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = \"load data here\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, features: pd.DataFrame, labels: pd.Series = None):\n",
    "        # TODO: Format the dataset class to match with the current image format\n",
    "        self.features = torch.tensor(features.values, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels.values, dtype=torch.int64)\\\n",
    "            if labels is not None else None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.labels is None:\n",
    "            return self.features[idx]\n",
    "        return self.features[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_frac = 0.8\n",
    "train_len = int(train_frac * len(train))\n",
    "train_data, validation_data = train.iloc[:train_len], train.iloc[train_len:]\n",
    "\n",
    "train_dataset = CustomDataset(train_data.drop(columns='label'), train_data['label'])\n",
    "validation_dataset = CustomDataset(train_data.drop(columns='label'), train_data['label'])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiabetesClassif(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(DiabetesClassif, self).__init__()\n",
    "        self.backbone = models.mobilenet_v3_large(pretrained=True)\n",
    "        self.backbone.classifier[3] = nn.Linear(self.backbone.classifier[3].in_features, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "model = DiabetesClassif(num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Validation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(model, epochs, optimizer, loss_fn, data):\n",
    "    for t in range(epochs):\n",
    "        loop = tqdm(data, total=len(data))\n",
    "        model.train()\n",
    "\n",
    "        for _, (X, y) in enumerate(loop):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            pred = model(X)\n",
    "            loss = loss_fn(pred, y)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loop.set_description(f\"Epoch [{t+1}/{epochs}]\")\n",
    "            loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    print(\"Training completed.\")\n",
    "\n",
    "def validation_loop(model, loss_fn, data):\n",
    "    model.eval()\n",
    "    size = len(data.dataset)\n",
    "    num_batches = len(data)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in data:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "        \n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "optimizer = AdamW(params=model.parameters)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# TODO: Prepare data processing and dataloader\n",
    "training_loop(model, epochs, optimizer, loss_fn, train_dataloader)\n",
    "validation_loop(model, loss_fn, validation_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
